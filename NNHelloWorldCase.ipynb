{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo 导入库\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667= 0.1111111111111111 + 0.6666666666666667\n",
      "1.0= 0.6666666666666667 + 1.0\n"
     ]
    }
   ],
   "source": [
    "trans = [ 1/9, 5/9,  3/9,]\n",
    "for i in range(1, len(trans)):\n",
    "\ttrans[i] = trans[i -1 ] + trans[i]\n",
    "\tprint('{}= {} + {}'.format(trans[i] , trans[i -1 ] , trans[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#todo 配置训练环境和超参数\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "'''配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs'''\n",
    "batch_size = 256\n",
    "num_workers = 4  # 对于Windows用户，这里应设置为0，否则会出现多线程错误\n",
    "lr = 1e-4\n",
    "epochs = 20\n",
    "print(device)\n",
    "torch.cuda.is_available()\n",
    "from torchvision.datasets import CIFAR10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#todo 读取数据【以fashMnist为例】\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),  #mark这一步取决于后续的数据读取方式，如果使用内置数据集则不需要\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "#读取方式一：使用torchvision自带数据集，下载可能需要一段时间\n",
    "from torchvision import datasets\n",
    "train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n",
    "test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "'''#读取方式二：读入csv格式的数据，自行构建Dataset类 ,\n",
    "dataset说明详见：https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E4%B8%89%E7%AB%A0/3.3%20%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%85%A5.html\n",
    "'''\n",
    "\n",
    "\n",
    "## 自行构建Dataset类,读入csv格式的数据，\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df  #传入的dataframe\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:, 1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28, 28, 1)  #输入是（1，764） 重新reshape\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image / 255., dtype=torch.float)  #读进来的数据转化成Tnesor\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(r\"D:\\D数据盘\\PycharmProjects\\pythonProject\\dataSet\\fashion-mnist\\fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(r\"D:\\D数据盘\\PycharmProjects\\pythonProject\\dataSet\\fashion-mnist\\fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1b1266672c8>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Dataloader加载数据\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "## 查看载入数据是否正确\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = next(iter(test_loader))\n",
    "print(image.shape,  label.shape)#迭代器每次迭代256张图出来image来接收，对于image来说就是一个256张单通道28*28的list（即256，1，28，28）\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0000, 0.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "print(image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#todo 模型设计[CNN为例]\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda()   # 多卡训练时的写法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#todo 设定损失函数,优化器\n",
    "'''\n",
    "使用torch.nn模块自带的CrossEntropy损失\n",
    "PyTorch会自动把整数型的label转为one-hot型，用于计算CE loss\n",
    "这里需要确保label是从0开始的，同时模型不加softmax层（使用logits计算）,这也说明了PyTorch训练中各个部分不是独立的，需要通盘考虑\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.686951\n",
      "Epoch: 1 \tValidation Loss: 0.471564, Accuracy: 0.830800\n",
      "Epoch: 2 \tTraining Loss: 0.432371\n",
      "Epoch: 2 \tValidation Loss: 0.355756, Accuracy: 0.873900\n",
      "Epoch: 3 \tTraining Loss: 0.367457\n",
      "Epoch: 3 \tValidation Loss: 0.315705, Accuracy: 0.882900\n",
      "Epoch: 4 \tTraining Loss: 0.332193\n",
      "Epoch: 4 \tValidation Loss: 0.279223, Accuracy: 0.898700\n",
      "Epoch: 5 \tTraining Loss: 0.308863\n",
      "Epoch: 5 \tValidation Loss: 0.285407, Accuracy: 0.896000\n",
      "Epoch: 6 \tTraining Loss: 0.291494\n",
      "Epoch: 6 \tValidation Loss: 0.263041, Accuracy: 0.905400\n",
      "Epoch: 7 \tTraining Loss: 0.278233\n",
      "Epoch: 7 \tValidation Loss: 0.251713, Accuracy: 0.907100\n",
      "Epoch: 8 \tTraining Loss: 0.262124\n",
      "Epoch: 8 \tValidation Loss: 0.239732, Accuracy: 0.909100\n",
      "Epoch: 9 \tTraining Loss: 0.252581\n",
      "Epoch: 9 \tValidation Loss: 0.232857, Accuracy: 0.911800\n",
      "Epoch: 10 \tTraining Loss: 0.245607\n",
      "Epoch: 10 \tValidation Loss: 0.241957, Accuracy: 0.907500\n",
      "Epoch: 11 \tTraining Loss: 0.235822\n",
      "Epoch: 11 \tValidation Loss: 0.225607, Accuracy: 0.916300\n",
      "Epoch: 12 \tTraining Loss: 0.226332\n",
      "Epoch: 12 \tValidation Loss: 0.231929, Accuracy: 0.915600\n",
      "Epoch: 13 \tTraining Loss: 0.220133\n",
      "Epoch: 13 \tValidation Loss: 0.221775, Accuracy: 0.916900\n",
      "Epoch: 14 \tTraining Loss: 0.214368\n",
      "Epoch: 14 \tValidation Loss: 0.215364, Accuracy: 0.921100\n",
      "Epoch: 15 \tTraining Loss: 0.208748\n",
      "Epoch: 15 \tValidation Loss: 0.227059, Accuracy: 0.913400\n",
      "Epoch: 16 \tTraining Loss: 0.200457\n",
      "Epoch: 16 \tValidation Loss: 0.223569, Accuracy: 0.916700\n",
      "Epoch: 17 \tTraining Loss: 0.191586\n",
      "Epoch: 17 \tValidation Loss: 0.207562, Accuracy: 0.921100\n",
      "Epoch: 18 \tTraining Loss: 0.186411\n",
      "Epoch: 18 \tValidation Loss: 0.215237, Accuracy: 0.919900\n",
      "Epoch: 19 \tTraining Loss: 0.185546\n",
      "Epoch: 19 \tValidation Loss: 0.211407, Accuracy: 0.921100\n",
      "Epoch: 20 \tTraining Loss: 0.177239\n",
      "Epoch: 20 \tValidation Loss: 0.203440, Accuracy: 0.922500\n"
     ]
    }
   ],
   "source": [
    "#todo 训练和测试（验证）\n",
    "'''\n",
    "各自封装成函数，方便后续调用\n",
    "关注两者的主要区别：\n",
    "    1：模型状态设置\n",
    "    2:是否需要初始化优化器\n",
    "    3:是否需要将loss传回到网络\n",
    "    4:是否需要每步更新optimizer\n",
    "'''\n",
    "def train(epoch):\n",
    "    model.train()#区别1\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()  ##区别2 清零梯度，即优化器初始化\n",
    "        #输入数据-》计算误差-》反向传播-》更新梯度\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()#区别4\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        '''\n",
    "        # data.size(0)是当前批次的样本数，乘以样本数是因为求误差公式1/n (y-yhat)^2，误差loss是所有样本的和再取平均。\n",
    "        所以在for单次是一个批次样本的loss总和，后面for外部就是总train_loss/len(train_loader.dataset)【总误差/除以整个数据集样本数量】\n",
    "        这也是为什么打印出来loss越来越大，因为是样本的误差和\n",
    "        '''\n",
    "        # print('train ===now train_loss is {}'.format(train_loss))\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():  #区别3\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output,1)  #返回指定维度最大值的序号,max是返回 value，idx【https://blog.csdn.net/qq_46092061/article/details/120612102】\n",
    "            gt_labels.append(label.cpu().data.numpy()) #添加这个batch中真实值的label\n",
    "            pred_labels.append(preds.cpu().data.numpy()) #添加这个batch中预测值的label\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "    val_loss = val_loss / len(test_loader.dataset)\n",
    "    ''' debug\n",
    "    print(len(gt_labels)) # 结果40,因为10000张图片10000/256=39.0625≈40\n",
    "    print(gt_labels) # 结果为一个含有40个list,每个list有256个预测值的list\n",
    "    '''\n",
    "    '''计算acc'''\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels) #合并真实值、预测值的标签\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#todo 保存/调用模型\n",
    "save_path = \"./FahionModel.pkl\"\n",
    "## 模型与参数一起保存\n",
    "torch.save(model, save_path)# model.state_dict()仅保存参数，重新使用时\n",
    "seq_net1 = torch.load(save_path)\n",
    "## 仅保存模型参数，需要重新建立模型才可使用\n",
    "torch.save(model.state_dict(), save_path)\n",
    "seq_net1 = Net()\n",
    "seq_net1.load_state_dict(torch.load(save_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not None:\n",
    "    print(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}